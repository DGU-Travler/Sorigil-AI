{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLIP 모델 임포트 및 버전 설정, GPU에 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T03:10:58.929709Z",
     "start_time": "2024-09-25T03:10:55.140472Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COCO 데이터셋 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T03:11:29.830721Z",
     "start_time": "2024-09-25T03:11:28.928096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.53s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.11s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from torchvision.datasets import CocoCaptions\n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# COCO 데이터셋 경로 설정\n",
    "train_dataset = CocoCaptions(root=r'E:\\CLIP_COCO\\train2017',\n",
    "                             annFile=r'E:\\CLIP_COCO\\annotations\\captions_train2017.json',\n",
    "                             transform=transform)\n",
    "\n",
    "val_dataset = CocoCaptions(root=r'E:\\CLIP_COCO\\val2017',\n",
    "                           annFile=r'E:\\CLIP_COCO\\annotations\\captions_val2017.json',\n",
    "                           transform=transform)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "로드된 데이터셋 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T03:11:32.008288Z",
     "start_time": "2024-09-25T03:11:31.984285Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: torch.Size([3, 480, 640])\n",
      "Caption: ['Closeup of bins of food that include broccoli and bread.', 'A meal is presented in brightly colored plastic trays.', 'there are containers filled with different kinds of foods', 'Colorful dishes holding meat, vegetables, fruit, and bread.', 'A bunch of trays that have different food.']\n"
     ]
    }
   ],
   "source": [
    "img, caption = train_dataset[0]\n",
    "print(\"Image size:\", img.size())\n",
    "print(\"Caption:\", caption)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
