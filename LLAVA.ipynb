{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "영문 원본 LLAVA - 허깅페이스에서 가져와서 pip 받을게 거의 없음"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8afe51053557ac0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from PIL import Image\n",
    "\n",
    "# 모델과 프로세서 로드\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
    "\n",
    "# 이미지 불러오기\n",
    "image = Image.open('/testimage/test.png')\n",
    "\n",
    "# 이미지를 pixel_values로 변환 (전처리)\n",
    "inputs = processor(image, return_tensors=\"pt\")\n",
    "\n",
    "# 캡션 생성\n",
    "outputs = model.generate(**inputs)\n",
    "caption = processor.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated caption:\", caption)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "OCR"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67db3a73975d3367"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import easyocr\n",
    "\n",
    "# EasyOCR 리더 초기화 (한글과 영어 지원)\n",
    "reader = easyocr.Reader(['ko', 'en'])\n",
    "\n",
    "# OCR 수행\n",
    "result = reader.readtext('/testimage/test6.png')\n",
    "text = '\\n'.join([res[1] for res in result])\n",
    "\n",
    "print(\"Generated OCR text:\", text)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3101657425831ee8",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "ocr, 캡션 합치기"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8cf27e5749b536e5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from PIL import Image\n",
    "import easyocr\n",
    "import numpy as np\n",
    "\n",
    "# BLIP 모델과 프로세서 로드\n",
    "blip_processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
    "blip_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
    "\n",
    "# EasyOCR 리더 초기화 (한글과 영어 지원)\n",
    "ocr_reader = easyocr.Reader(['ko', 'en'])\n",
    "\n",
    "# 이미지 불러오기\n",
    "image = Image.open('/testimage/test.png').convert('RGB')\n",
    "\n",
    "# 1. EasyOCR을 사용하여 이미지 내 텍스트 추출 (PIL 이미지를 numpy 배열로 변환)\n",
    "ocr_result = ocr_reader.readtext(np.array(image))\n",
    "ocr_text = ' '.join([res[1] for res in ocr_result])\n",
    "\n",
    "# 2. BLIP를 사용하여 이미지 캡션 생성\n",
    "inputs = blip_processor(image, return_tensors=\"pt\")\n",
    "outputs = blip_model.generate(**inputs)\n",
    "caption = blip_processor.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# 3. OCR 결과와 BLIP 캡션 결합\n",
    "combined_caption = f\"OCR Text: {ocr_text}\\nGenerated Caption: {caption}\"\n",
    "\n",
    "print(combined_caption)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c50761b069a5a4",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "한글 llava 시도"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a125eec710befa90"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"KBNIT/KoLLaVA-1.5v-kolon-v1.6\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"KBNIT/KoLLaVA-1.5v-kolon-v1.6\")\n",
    "\n",
    "# 이미지 불러오기\n",
    "image = Image.open('test4.png')\n",
    "\n",
    "# 이미지를 pixel_values로 변환 (전처리)\n",
    "inputs = processor(image, return_tensors=\"pt\")\n",
    "\n",
    "# 캡션 생성\n",
    "outputs = model.generate(**inputs)\n",
    "caption = processor.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated caption:\", caption)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8385053d7ef698c2",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "허깅페이스 api 호출"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa58ece3d4c092ad"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# .env 파일 로드\n",
    "load_dotenv()\n",
    "\n",
    "# 환경 변수에서 Hugging Face API 토큰 가져오기\n",
    "api_token = os.getenv('HUGGING_FACE_API')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-29T15:28:15.242792Z",
     "start_time": "2024-09-29T15:28:15.224846Z"
    }
   },
   "id": "97802fa26947d5db",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "import base64\n",
    "\n",
    "# 이미지 파일을 읽어서 base64로 변환\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "# Hugging Face API 호출 함수\n",
    "def query(image_path):\n",
    "    API_URL = \"https://api-inference.huggingface.co/models/Salesforce/blip-image-captioning-large\"\n",
    "    headers = {\"Authorization\": f\"Bearer {api_token}\"}  # Hugging Face API 토큰\n",
    "    image_data = encode_image(image_path)\n",
    "\n",
    "    # API 요청 데이터 (이미지를 base64로 변환 후 전송)\n",
    "    payload = {\n",
    "        \"inputs\": {\n",
    "            \"image\": image_data\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # API 호출\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    return response.json()\n",
    "\n",
    "# 이미지 파일 경로\n",
    "image_path = 'test4.png'\n",
    "\n",
    "# 결과 출력\n",
    "result = query(image_path)\n",
    "print(\"Generated caption:\", result)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd9e95ac21d06713",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
