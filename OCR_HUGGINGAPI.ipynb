{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import easyocr\n",
    "import requests\n",
    "from PIL import Image\n",
    "import base64\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "\n",
    "# .env 파일 로드\n",
    "load_dotenv()\n",
    "\n",
    "# 환경 변수에서 Hugging Face API 토큰 가져오기\n",
    "api_token = os.getenv('HUGGING_FACE_API')\n",
    "client = OpenAI(\n",
    "  api_key=os.getenv(\"GPT_API\"),  # this is also the default, it can be omitted\n",
    ")\n",
    "\n",
    "# EasyOCR 리더 초기화 (한글과 영어 지원)\n",
    "ocr_reader = easyocr.Reader(['ko', 'en'])\n",
    "\n",
    "# 이미지 불러오기\n",
    "image_path = './testimage/test6.png'\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "# 이미지 파일을 읽어서 base64로 변환\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "# 1. EasyOCR을 사용하여 이미지 내 텍스트 추출 (PIL 이미지를 numpy 배열로 변환)\n",
    "ocr_result = ocr_reader.readtext(np.array(image))\n",
    "ocr_text = ' '.join([res[1] for res in ocr_result])\n",
    "\n",
    "# Hugging Face API 호출 함수\n",
    "def query(image_path):\n",
    "    API_URL = \"https://api-inference.huggingface.co/models/Salesforce/blip-image-captioning-large\"\n",
    "    headers = {\"Authorization\": f\"Bearer {api_token}\"}  # Hugging Face API 토큰\n",
    "    image_data = encode_image(image_path)\n",
    "\n",
    "    # API 요청 데이터 (이미지를 base64로 변환 후 전송)\n",
    "    payload = {\n",
    "        \"inputs\": {\n",
    "            \"image\": image_data\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # API 호출\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    return response.json()\n",
    "\n",
    "# 결과 출력\n",
    "result = query(image_path)\n",
    "combined_caption = f\"OCR Text: {ocr_text}\\nGenerated Caption: {result}\"\n",
    "\n",
    "print(combined_caption)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
